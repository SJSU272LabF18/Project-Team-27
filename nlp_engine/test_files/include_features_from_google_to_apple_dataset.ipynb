{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Features like number of installs, age group, etc\n",
    "## The code works but finding similar app name between the 2 dataset and including new column values for each app name will take around 10 hours\n",
    "## Another solution is - finding similar app name in the google dataset sparse array, everytime a new decription is entered in real time\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer ## TFIDF calculation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer ## pos tagging and lemmatization\n",
    "from nltk.corpus import wordnet\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "from nltk.tokenize import RegexpTokenizer ## Tokenizer which removes punctuation\n",
    "\n",
    "import pandas as pd ## Read and manipulate csv\n",
    "\n",
    "from langdetect import detect ## Detect Language\n",
    "\n",
    "import pickle ## pickle the model\n",
    "\n",
    "# import numpy\n",
    "# numpy.set_printoptions(threshold=numpy.nan) ## To print the full NumPy array when jupyter notebook truncates the stdout with ... in between\n",
    "\n",
    "## Reading from csv using pandas\n",
    "path = 'C:\\\\Users\\\\shrke\\\\Desktop\\\\272 Project\\\\Google store dataset\\\\'\n",
    "data_full = pd.read_csv(path + \"googleplaystore.csv\")\n",
    "\n",
    "\n",
    "\n",
    "description_array = []\n",
    "## Array that stores all descriptions\n",
    "\n",
    "        \n",
    "\n",
    "## Append all descriptions into a single array\n",
    "for i in range(len(data_full)):  \n",
    "    description_array.append(data_full.iloc[i]['App'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8582\n"
     ]
    }
   ],
   "source": [
    "description_array[0]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english')   \n",
    "\n",
    "## tokenize and build vocabulary\n",
    "vectorizer.fit(description_array)\n",
    "print (len(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents_encoded = []\n",
    "for i in range(len(description_array)):\n",
    "    vector = vectorizer.transform([description_array[i]]) ## make sparse array\n",
    "    ## summarize encoded vector\n",
    "    vector_array = vector.toarray()\n",
    "    all_documents_encoded.append(vector_array[0]) \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_documents_encoded[1] \n",
    "print (len(all_documents_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PAC-MAN'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_array[3913]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = 'C:\\\\Users\\\\shrke\\\\Desktop\\\\272 Project\\\\Apple store dataset\\\\'\n",
    "data_full1 = pd.read_csv(path1 + \"AppleStore.csv\")\n",
    "data_full1['installs'] = 0\n",
    "data_full1.to_csv(path1 + \"AppleStore.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full1.loc[1,'Installs']= data_full.iloc[3913]['Installs']\n",
    "data_full1.to_csv(path1 + \"AppleStore.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAC-MAN Premium\n",
      "3913\n",
      "100,000,000+\n",
      "100,000,000+\n",
      "Evernote - stay organized\n",
      "4800\n",
      "100,000,000+\n",
      "100,000,000+\n",
      "WeatherBug - Local Weather, Radar, Maps, Alerts\n",
      "3630\n",
      "10,000,000+\n",
      "100,000,000+\n",
      "eBay: Best App to Buy, Sell, Save! Online Shopping\n",
      "2753\n",
      "5,000,000+\n",
      "10,000,000+\n",
      "Bible\n",
      "3941\n",
      "100,000,000+\n",
      "5,000,000+\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\shrke\\\\Desktop\\\\272 Project\\\\Apple store dataset\\\\AppleStore.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-5f45a9a85b74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata_full1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Installs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mdata_full1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Installs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdata_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mall_documents_similarity_sorted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Installs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mdata_full1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"AppleStore.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1743\u001b[0m                                  \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                                  escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1745\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    154\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m    155\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m    157\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;31m# Python 3 and encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\shrke\\\\Desktop\\\\272 Project\\\\Apple store dataset\\\\AppleStore.csv'"
     ]
    }
   ],
   "source": [
    "def sortTopXpercent(all_documents_similarity, topXpercent):\n",
    "\n",
    "    x = 1\n",
    "    while(x<=topXpercent):\n",
    "\n",
    "        for i in range(len(all_documents_similarity)-1, -1, -1):\n",
    "            \n",
    "            if(i == 0):\n",
    "                continue\n",
    "            if(all_documents_similarity[i]>all_documents_similarity[i-1]):\n",
    "                temp = all_documents_similarity[i]\n",
    "                all_documents_similarity[i] = all_documents_similarity[i-1]\n",
    "                all_documents_similarity[i-1] = temp\n",
    "                \n",
    "        x = x+1\n",
    "\n",
    "    all_documents_similarity_sorted_topXpercent = all_documents_similarity[:topXpercent]\n",
    "\n",
    "    return all_documents_similarity_sorted_topXpercent\n",
    "\n",
    "for i in range(0, 7197):\n",
    "    test_description_modified = data_full1.iloc[i]['track_name']\n",
    "    print (test_description_modified)\n",
    "    test_document_vector = vectorizer.transform([test_description_modified])\n",
    "    test_document_encoded = (test_document_vector.toarray()) \n",
    "    #print (test_description_modified)\n",
    "    \n",
    "    \n",
    "    ## Cosine Similarity:\n",
    "    all_documents_similarity = []\n",
    "    ## all_documents_similarity is a array in which we save the similarity and the primary key/index together as we will have to sort the list for selecting top similar descriptions, so we need to save the indexes as well\n",
    "    for i in range(len(all_documents_encoded)):\n",
    "        all_documents_similarity.append([cosine_similarity([all_documents_encoded[i]],test_document_encoded), i])\n",
    "\n",
    "    ## Sort all similarities in desc order    \n",
    "    all_documents_similarity_sorted = sortTopXpercent(all_documents_similarity, 1) \n",
    "    print (all_documents_similarity_sorted[0][1])\n",
    "    print (data_full.iloc[all_documents_similarity_sorted[0][1]]['Installs'])\n",
    "    print (data_full1.loc[(i-1),'Installs'])\n",
    "    data_full1.loc[(i-1),'Installs']= data_full.iloc[all_documents_similarity_sorted[0][1]]['Installs']\n",
    "    data_full1.to_csv(path1 + \"AppleStore.csv\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3913"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
